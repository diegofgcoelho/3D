/*
 * match.cpp
 *
 *  Created on: May 16, 2017
 *      Author: Diego Coelho, PhD Candidate, UofC
 */

#include "opencv2/opencv.hpp"
#include "opencv2/videoio.hpp"
#include "opencv2/features2d.hpp"
#include "opencv2/xfeatures2d.hpp"

#define SUCCESS 0
#define FAIL -1
#define FILE_FAIL -2

using namespace cv;
using namespace cv::xfeatures2d;
using namespace std;

int readframes(String, unsigned, vector<Mat*>**);
int matchframes(vector<Mat*>**, vector<DMatch*>**);

int main(int argc, char** argv){
	//Create pointer for STL vector containing all the frames
	vector<Mat*>* vecframes = new vector<Mat*>();
	//Defining subsampling constant
	unsigned int stride = 10;
	//Reading frames from video
	int readframes_code = readframes("vid_sample.mp4", stride, &vecframes);
	//Checking if the reading was successful
	if(readframes_code != SUCCESS){
		cout << "Error: problem reading video frames. Exiting ..." << endl;
		return FAIL;
	}





}

int readframes(String filename, unsigned stride, vector<Mat*>** vecframes){
	/*
	 * Input:
	 * filename is the string representing the file containing the video
	 * stride represent the decimation constant for the frames to be read
	 * Output:
	 * vecframe is a vector or pointers for matrices containing the frames
	 * that will be used for processing
	 * Description:
	 * this function read the frames from a video file with name filename and
	 * undersample the frames according the constant stride (eg, if stride=2,
	 * it will take only every other frame, if stride=3, it will take only one
	 * in every 3 frames) and return in the vector of pointers for matrices that
	 * store the frames
	 */

	//Video object that will be used for opening the video file
	VideoCapture vid(filename);

	//Opening the video
	vid.open(filename);
	//Sanity check
	if(!vid.isOpened()){
		cout << "Error: it is not possible to read the video file " << filename << endl;
		return FILE_FAIL;
	}

	//Reading the total number of frames in the video object
	unsigned int frame_count = vid.get(CV_CAP_PROP_FRAME_COUNT);
	//Resizing the vector
	(*vecframes)->resize(floor(frame_count/stride));

	//Frame index
	unsigned int frame_index = 0;

	for(unsigned int i = 0; i < floor(frame_count/stride); i++){
		//Updating the frame index
		frame_index += stride;
		//Setting frame index to be read
		vid.set(CV_CAP_PROP_POS_FRAMES, frame_index);
		//Creating matrix
		Mat* frame = new Mat;
		//Reading frame
		vid >> *frame;
		//Setting elements in the output vector
		(*(*vecframes))[i] = frame;
	}

	return SUCCESS;
}

int matchframes(vector<Mat*>** vecframes, vector<DMatch*>** vecmatches){
	/*
	 * Input:
	 * vecframes contains the frames from the video that was read and will be processed.
	 * Output:
	 * vecmatches contains the matches between the subsequent frames from the video
	 * to be processed.
	 * Description:
	 * this function performs the feature description, extraction and matching between the
	 * frames from the video to be processed. Currently, it used brute force matching
	 * (it needs to be changed) between the features on neighbor frames.
	 */

	//Resizing the vecmatches
	(*vecmatches)->resize((*vecframes)->size());

	//Defining detector that will be used for detecting the features in all frames
	Ptr<SURF> detector = SURF::create(400, 4, 3, false, false);
	//Vector of vector of keypoints. We need one keypoint matrix for each frame
	vector<vector< KeyPoint> >* veckeypoints = new vector< vector<KeyPoint> >((*vecframes)->size());

	for(unsigned int i = 0; i < (*vecframes)->size(); i++){
		//Calling the detection with each keypoint
		detector->detect((*(*vecframes)->at(i)), veckeypoints->at(i));

	}
















//#include <stdio.h>
//#include <iostream>
//#include "opencv2/core.hpp"
//#include "opencv2/features2d.hpp"
//#include "opencv2/xfeatures2d.hpp"
//#include "opencv2/highgui.hpp"
//
//using namespace cv;
//using namespace cv::xfeatures2d;
//
//void readme();
//
///** @function main */
//int main( int argc, char** argv )
//{
//  if( argc != 3 )
//  { readme(); return -1; }
//
//  Mat img_1 = imread( argv[1], IMREAD_GRAYSCALE );
//  Mat img_2 = imread( argv[2], IMREAD_GRAYSCALE );
//
//  if( !img_1.data || !img_2.data )
//  { std::cout<< " --(!) Error reading images " << std::endl; return -1; }
//
//  //-- Step 1: Detect the keypoints using SURF Detector
//  int minHessian = 400;
//
//  Ptr<SURF> detector = SURF::create(minHessian , 4, 3, false, false);
//
//  std::vector<KeyPoint> keypoints_1, keypoints_2;
//
//  detector->detect( img_1, keypoints_1 );
//  detector->detect( img_2, keypoints_2 );
//
//  //-- Draw keypoints
//  Mat img_keypoints_1; Mat img_keypoints_2;
//
//  drawKeypoints( img_1, keypoints_1, img_keypoints_1, Scalar::all(-1), DrawMatchesFlags::DEFAULT );
//  drawKeypoints( img_2, keypoints_2, img_keypoints_2, Scalar::all(-1), DrawMatchesFlags::DEFAULT );
//
//  //-- Show detected (drawn) keypoints
//  imshow("Keypoints 1", img_keypoints_1 );
//  imshow("Keypoints 2", img_keypoints_2 );
//
//  waitKey(0);
//
//  return 0;
//  }
//
//  /** @function readme */
//  void readme()
//  {
//	  std::cout << " Usage: ./SURF_detector <img1> <img2>" << std::endl;
//  }
//











