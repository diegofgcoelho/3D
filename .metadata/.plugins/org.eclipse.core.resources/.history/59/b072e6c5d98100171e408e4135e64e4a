/*
 * recon.cpp
 *
 *  Created on: Aug 10, 2017
 *      Author: Diego, PhD Candidate, UofC
 */

#define CERES_FOUND true

#include <opencv2/opencv.hpp>
#include <opencv2/sfm.hpp>
#include <opencv2/viz.hpp>
#include <opencv2/calib3d.hpp>
#include <opencv2/core.hpp>
#include <opencv2/features2d.hpp>
#include <opencv2/xfeatures2d.hpp>
#include <opencv2/highgui.hpp>
#include <iostream>
#include <fstream>

#define SUCCESS 0
#define FAIL -1
#define FILE_FAIL -2

using namespace std;
using namespace cv;
using namespace cv::xfeatures2d;
using namespace cv::sfm;


static void help();
int readframes(String filename, unsigned stride, vector<Mat*>** vecframes);
int matchframes(vector<Mat*>** vecframes, vector< vector<KeyPoint>* >** veckeypoints, vector< vector<DMatch>* >** vecmatches);
int gen2DpointsTable(vector< vector<DMatch>* >* vecmatches, vector< vector<KeyPoint>* >* veckeypoints, vector<Mat>** points);
int shape2Dpoints(vector< vector<DMatch>* >* vecmatches, vector< vector<KeyPoint>* >* veckeypoints, vector<Mat>** points);


int main(int argc, char* argv[])
{
  // Read input parameters
  if ( argc != 5 )
  {
    help();
    exit(0);
  }

  //Printing the video name
  cout << argv[1] << endl;


  // Build instrinsics
  float f  = atof(argv[2]),
        cx = atof(argv[3]), cy = atof(argv[4]);
  Matx33d K = Matx33d( f, 0, cx,
                       0, f, cy,
                       0, 0,  1);
  bool is_projective = true;
  vector<Mat> Rs_est, ts_est, points3d_estimated;

  //Create pointer for STL vector containing all the frames
  vector<Mat*>* vecframes = NULL;
  //Defining subsampling constant
  unsigned int stride = 5;
  //Reading frames from video
  int readframes_code = readframes(argv[1], stride, &vecframes);

  //Checking if the reading was successful
  if(readframes_code != SUCCESS){
  	  cout << "Error: problem reading video frames. Exiting ..." << endl;
	  return FAIL;
  } else {
	  cout << "Frame read successfully." << endl;
  }

  //Creating the vector of vectors of DMatch. Each matching needs a vector of DMatch.
  vector< vector<DMatch>* >* vecmatches = NULL;
  vector< vector<KeyPoint>* >* veckeypoints = NULL;
  int matchframes_code = matchframes(&vecframes, &veckeypoints, &vecmatches);

  if(matchframes_code != SUCCESS){
	  cout << "Error: problem when matching the frames. Exiting ..." << endl;
	  return FAIL;
  } else {
	  cout << "Frames matched successfully." << endl;
  }

  vector<Mat>* points = NULL;
  int shape2D_code = gen2DpointsTable(vecmatches, veckeypoints, &points);

  if(shape2D_code != SUCCESS){
	  cout << "Error: problem when reorganizing the 2D points. Exiting ..." << endl;
	  return FAIL;
  } else {
	  cout << "Points reorganized successfully." << endl;
  }

  reconstruct(*points, Rs_est, ts_est, K, points3d_estimated, is_projective);
  // Print output
  cout << "\n----------------------------\n" << endl;
  cout << "Reconstruction: " << endl;
  cout << "============================" << endl;
  cout << "Estimated 3D points: " << points3d_estimated.size() << endl;
  cout << "Estimated cameras: " << Rs_est.size() << endl;
  cout << "Refined intrinsics: " << endl << K << endl << endl;
  cout << "3D Visualization: " << endl;
  cout << "============================" << endl;
  viz::Viz3d window("Coordinate Frame");
             window.setWindowSize(Size(500,500));
             window.setWindowPosition(Point(150,150));
             window.setBackgroundColor(); // black by default
  // Create the pointcloud
  cout << "Recovering points  ... ";
  // recover estimated points3d
  vector<Vec3f> point_cloud_est;
  for (unsigned int i = 0; i < points3d_estimated.size(); ++i)
    point_cloud_est.push_back(Vec3f(points3d_estimated[i]));
  cout << "[DONE]" << endl;
  cout << "Recovering cameras ... ";
  vector<Affine3d> path;
  for (size_t i = 0; i < Rs_est.size(); ++i)
    path.push_back(Affine3d(Rs_est[i],ts_est[i]));
  cout << "[DONE]" << endl;
  if ( point_cloud_est.size() > 0 )
  {
    cout << "Rendering points   ... ";
    viz::WCloud cloud_widget(point_cloud_est, viz::Color::green());
    window.showWidget("point_cloud", cloud_widget);
    cout << "[DONE]" << endl;
  }
  else
  {
    cout << "Cannot render points: Empty pointcloud" << endl;
  }
  if ( path.size() > 0 )
  {
    cout << "Rendering Cameras  ... ";
    window.showWidget("cameras_frames_and_lines", viz::WTrajectory(path, viz::WTrajectory::BOTH, 0.1, viz::Color::green()));
    window.showWidget("cameras_frustums", viz::WTrajectoryFrustums(path, K, 0.1, viz::Color::yellow()));
    window.setViewerPose(path[0]);
    cout << "[DONE]" << endl;
  }
  else
  {
    cout << "Cannot render the cameras: Empty path" << endl;
  }
  cout << endl << "Press 'q' to close each windows ... " << endl;
  window.spin();
  return 0;
}




static void help() {
  cout
      << "\n------------------------------------------------------------------------------------\n"
      << " This program shows the multiview reconstruction capabilities in the \n"
      << " OpenCV Structure From Motion (SFM) module.\n"
      << " It reconstruct a scene from a set of 2D images \n"
      << " Usage:\n"
      << "        example_sfm_scene_reconstruction <path_to_file> <f> <cx> <cy>\n"
      << " where: path_to_file is the file absolute path into your system which contains\n"
      << "        the list of images to use for reconstruction. \n"
      << "        f  is the focal lenght in pixels. \n"
      << "        cx is the image principal point x coordinates in pixels. \n"
      << "        cy is the image principal point y coordinates in pixels. \n"
      << "------------------------------------------------------------------------------------\n\n"
      << endl;
}

int readframes(String filename, unsigned stride, vector<Mat*>** vecframes){
	/*
	 * Input:
	 * filename is the string representing the file containing the video
	 * stride represent the decimation constant for the frames to be read
	 * Output:
	 * vecframe is a vector or pointers for matrices containing the frames
	 * that will be used for processing
	 * Description:
	 * this function read the frames from a video file with name filename and
	 * undersample the frames according the constant stride (eg, if stride=2,
	 * it will take only every other frame, if stride=3, it will take only one
	 * in every 3 frames) and return in the vector of pointers for matrices that
	 * store the frames. The memory for the pointer is allocated inside the function
	 * and must be released by the calling function.
	 */

	//Allocating memory for vecframes
	*vecframes = new vector<Mat*>();

	//Video object that will be used for opening the video file
	VideoCapture vid(filename);

	//Opening the video
	vid.open(filename);
	//Sanity check
	if(!vid.isOpened()){
		cout << "Error: it is not possible to read the video file " << filename << endl;
		return FILE_FAIL;
	}

	//Reading the total number of frames in the video object
	unsigned int frame_count = vid.get(CV_CAP_PROP_FRAME_COUNT);
	//Resizing the vector
	(*vecframes)->resize(floor(frame_count/stride));

	//Frame index
	unsigned int frame_index = 0;

	for(unsigned int i = 0; i < floor(frame_count/stride); i++){
		//Updating the frame index
		frame_index += stride;
		//Setting frame index to be read
		vid.set(CV_CAP_PROP_POS_FRAMES, frame_index);
		//Creating matrix
		Mat* frame = new Mat;
		//Reading frame
		vid >> *frame;
		//Setting elements in the output vector
		(*(*vecframes))[i] = frame;
	}

	return SUCCESS;
}

int matchframes(vector<Mat*>** vecframes, vector< vector<KeyPoint>* >** veckeypoints, vector< vector<DMatch>* >** vecmatches){
	/*
	 * Input:
	 * vecframes contains the frames from the video that was read and will be processed.
	 * Output:
	 * vecmatches contains the matches between the subsequent frames from the video
	 * to be processed.
	 * veckeypoints contains the keypoints for each frame
	 * Description:
	 * this function performs the feature description, extraction and matching between the
	 * frames from the video to be processed. Currently, it used brute force matching
	 * (it needs to be changed) between the features on neighbor frames. This function also
	 * eliminates bad matches by removing matches whose Euclidean distances are greater than a
	 * minimum (see code to check the treshold). This function also removes bad matches whose
	 * angle formed by the features in the query and train keypoints exceed a maximum angle. This
	 * agle is defined by setting both frames side by side and connecting the corresponding keypoints
	 * and measuring the angle formed with the horizontal.
	 */

	//Allocating and resizing the vecmatches and veckeypoints
	*vecmatches = new vector< vector<DMatch>* >();
	*veckeypoints = new vector< vector<KeyPoint>* >();
	(*vecmatches)->resize((*vecframes)->size()-1);
	(*veckeypoints)->resize((*vecframes)->size());

	//Defining detector that will be used for detecting the features in all frames. Using default values
	Ptr<SURF> detector = SURF::create(400, 4, 3, false, false);

	//Defining the descriptors for the frames that will be used inside the for loop
	Mat descriptors_0, descriptors_1;

	//Allocating memory for the keypoints of the first frame
	(*veckeypoints)->at(0) = new vector<KeyPoint>();
	//Computing the keypoints for the first frame
	detector->detect((*(*vecframes)->at(0)), (*(*veckeypoints)->at(0)));
	//Computing the descriptors for the first frame
	detector->compute((*(*vecframes)->at(0)), (*(*veckeypoints)->at(0)), descriptors_1);

	for(unsigned int i = 0; i < (*vecframes)->size()-1; i++){
		//Allocating memory for the keypoints of the (i+1)th frame
		(*veckeypoints)->at(i+1) = new vector<KeyPoint>();

		//Shifting the descriptors for performance
		descriptors_0 = descriptors_1;

		//Defining the descriptor matcher
		//Ptr<DescriptorMatcher> matcher = BFMatcher::create("BruteForce");
		Ptr<DescriptorMatcher> matcher = BFMatcher::create();

		//Detecting keypoints for frame i+1
		detector->detect((*(*vecframes)->at(i+1)), (*(*veckeypoints)->at(i+1)));

		//Computing descriptors for frame i+1
		detector->compute((*(*vecframes)->at(i+1)), (*(*veckeypoints)->at(i+1)), descriptors_1);

		//Matching the features for frames i and i+1
		(*vecmatches)->at(i) = new vector<DMatch>();
		matcher->match(descriptors_0, descriptors_1, (*(*vecmatches)->at(i)));

		//Removing bad matches
		vector<DMatch>* pvecm = (*vecmatches)->at(i);
		vector<KeyPoint>* pveck0 = (*veckeypoints)->at(i);
		vector<KeyPoint>* pveck1 = (*veckeypoints)->at(i+1);

		//Specifying a treshold to delete bad matches. Any matches whose distance is greater than treshold will be deleted.
		double dtreshold = 500;
		double atreshold = cos(5*M_PI/180);//When changing, remember that the argument have to be in the first quadrant!
		unsigned int j = 0;
		while (j < pvecm->size()){//Note how the index j is incremented
			//Getting the positions of the query and train keypoints
			Point2f kp0 = pveck0->at(pvecm->at(j).queryIdx).pt;
			Point2f kp1 = pveck1->at(pvecm->at(j).trainIdx).pt;
			Point2f dkp = kp1-kp0;
			//Computing the Euclidean distance between the pixels of the matching keypoints
			double dist = norm(dkp);
			//Computing the angle between the keypoints when images are side by side
			Point2f framedim = Point2f((*vecframes)->at(0)->rows, 0.0);
			//Shift only kp1
			kp1 = kp1+framedim;
			//Updating dkp (the difference between the keypoint of frame i and the shifted keypoint of frame i+1)
			dkp = kp1-kp0;
			double ang = dkp.x/norm(dkp);
			//Eliminating matches whose distance is greater than the minimum
			if((dist > dtreshold) || (fabs(ang) < atreshold)) pvecm->erase(pvecm->begin()+j); else j++;
		}
	}
	return SUCCESS;
}

int gen2DpointsTable(vector< vector<DMatch>* >* vecmatches, vector< vector<KeyPoint>* >* veckeypoints, vector<Mat>** points){
	/*
	 * Input:
	 * vecmatches contains the matches between the subsequent video frames
	 * veckeypoints contains the keypoints for each frame
	 * Output:
	 * points is the 2D points organized in the way that the method sfm::reconstruct needs
	 * Description:
	 * This function basically generate a vector of Mat objects which contain the corresponding 2D points
	 * in a format that is adequate to the method sfm::reconstruct. Each element of the vector, that is a Mat
	 * object, contains all the points detected to the corresponding frame. The Mat objects have 2 rows and ncol
	 * columns, where ncol is the total number of different points found during the feature detection and matching
	 * process. The firts row contains the x positions and the second the y positions of each point in that particular
	 * frame. When a point is not found on that frame (due to occlusion or numerical mistakes), the coordinates are
	 * set to -1.
	 */

	/*
	 * This vector of vector of integers represents the ID for each keypoint. If the point foes not have an corresponding point,
	 * a new ID is created to it.
	 */
	vector< vector<int> > vecID(veckeypoints->size());
	vecID[0] = vector<int>((*veckeypoints)[0]->size());
	for(unsigned int i = 0; i < (*veckeypoints)[0]->size(); i++) vecID[0][i] = i;

	unsigned int maxInd = veckeypoints[0].size()-1;

	for(unsigned int i = 1; i < veckeypoints->size(); i++){
		//cout << "entrou i = " << i << endl;
		//Create a new vector to be put in position i of the vector of vectors
		vecID[i] = vector<int>(veckeypoints->at(i)->size(), -1);

		//cout << "passou i = " << i << endl;

		//Run over all the matches
		for(unsigned int j = 0; j < (*vecmatches)[i-1]->size(); j++){

			//Extract the query and train index
			int queryInd = (*vecmatches)[i-1]->at(j).queryIdx;
			int trainInd = (*vecmatches)[i-1]->at(j).trainIdx;

			//Determine the index
			int index = vecID[i-1][queryInd];

			//cout << "i = " << i << " out of " << vecmatches->size() << " j = " << j << " out of " << (*vecmatches)[i-1]->size() << endl;

			/*
			 * If the index is -1, which means that this element have not been matched so far,
			 * we create add one -1 to the vector of negative indexes and the new indexes
			 */
			if(index == -1){
				maxInd++;
				vecID[i-1][queryInd] = maxInd;
				vecID[i][trainInd] = maxInd;
			}else{
				vecID[i][trainInd] = index;
			}
		}
	}


	cout << "out of the for with maxID = " << maxInd << endl;

	/*
	 * Up to this point, it is assumed that now we have the indexes in the vecID vector of vector of ints. We
	 * now start to build the table with the actual 2D points.
	 */

	*points = new vector<Mat>();
	(*points)->reserve(vecID.size());

	cout << "size = " << vecID.size() << endl;

	for(unsigned int i = 0; i < vecID.size(); i++){
		Mat_<double> mat(2,maxInd);

	}

	for(unsigned int i = 0; i < vecID.size(); i++){

		cout << "Entering i = " << i << " maxID " << maxInd << endl;
		//Defining the matrix for position i
		Mat_<double> mat(2,maxInd);

		if(mat.empty()){
			cout << "Matrix not allocated. Exiting ..." << endl;
			exit(-1);
		}

		cout << "mat defined" << endl;
		//Filling the matrix for position i
		for(unsigned int j = 0; j < vecID[i].size(); j++){
			//If the index is negative, we could not resolve which is the index

			cout << "i = " << i << " out of " << vecID.size() << " j = " << j << " out of " << vecID[i].size() << endl;
			if(vecID[i][j] == -1){
				mat(0,vecID[i][j]) = -1;
				mat(1,vecID[i][j]) = -1;
			} else {
				mat(0,vecID[i][j]) = (*veckeypoints)[i]->at(j).pt.x;
				mat(1,vecID[i][j]) = (*veckeypoints)[i]->at(j).pt.y;
			}

		}

		//Passing the matrix the matrix to position i in points
		(**points).push_back(Mat(mat));
	}
	cout << "Saiu " << endl;

	return SUCCESS;
}


//this functon dont work properly ... redo
int shape2Dpoints(vector< vector<DMatch>* >* vecmatches, vector< vector<KeyPoint>* >* veckeypoints, vector<Mat>** points){
	/*
	 * Input:
	 * vecmatches contains the matches between the subsequent video frames
	 * veckeypoints contains the keypoints for each frame
	 * Output:
	 * points is the 2D points organized in the way that the method sfm::reconstruct needs
	 * Description:
	 * This function basically generate a vector of Mat objects which contain the corresponding 2D points
	 * in a format that is adequate to the method sfm::reconstruct. Each element of the vector, that is a Mat
	 * object, contains all the points detected to the corresponding frame. The Mat objects have 2 rows and ncol
	 * columns, where ncol is the total number of different points found during the feature detection and matching
	 * process. The firts row contains the x positions and the second the y positions of each point in that particular
	 * frame. When a point is not found on that frame (due to occlusion or numerical mistakes), the coordinates are
	 * set to -1.
	 */

	/*
	 * This vector of vector of integers represents the ID for each keypoint. If the point foes not have an corresponding point,
	 * a new ID is created to it.
	 */
	vector< vector<int> > vecID(veckeypoints->size());
	vecID[0] = vector<int>((*veckeypoints)[0]->size());
	for(unsigned int i = 0; i < (*veckeypoints)[0]->size(); i++) vecID[0][i] = i;



	//Run over all the vector elements
	for(unsigned int i = 1; i <  vecmatches->size(); i++){

		cout << "passou i = " << i << " of a total = " << (*veckeypoints).size() << endl;
		//Create a new vector to be put in position i of the vector of vectors
		vecID[i] = vector<int>((*vecmatches)[i-1]->size(), -1);

		//declare the vectors containing the new points not match so far
		vector<int> vecnewpoints;
		vector<int> negindexes;


		//Run over all the matches
		for(unsigned int j = 0; j < (*vecmatches)[i-1]->size(); j++){

			//Extract the query and train index
			int queryInd = (*vecmatches)[i-1]->at(j).queryIdx;
			int trainInd = (*vecmatches)[i-1]->at(j).trainIdx;

			//Determine the index
			cout << "vecID[" << i-1 <<"].size() = " << vecID[i-1].size() << endl;
			cout << "vecID[" << i <<"].size() = " << vecID[i].size() << endl;
			cout << "quaeryInd = " << queryInd << endl;
			int index = vecID[i-1][queryInd];

			/*
			 * If the index is -1, which means that this element have not been matched so far,
			 * we create add one -1 to the vector of negative indexes and the new indexes
			 */
			cout << "i = " << i << " j = " << j << " out of " << (*vecmatches)[i-1]->size() << endl;
			if(index == -1){
				negindexes.push_back(-1);
				vecnewpoints.push_back(j);

				cout << "One negative" << endl;
			}else{
				vecID[i][trainInd] = index;
			}
		}

		cout << "saiu do for " << endl;

		//If any no matched element was found, update all the vector of indexes created so far and the current one
		if(negindexes.size()!=0){
			cout << "Entrou if" << endl;
			for(unsigned int j = 0; j < i; j++){
				vecID[j].insert(vecID[j].end(), negindexes.begin(), negindexes.end());
				cout << "this for j = " << j << endl;
			}
			cout << "doing the append vecnewpoints size = " << vecnewpoints.size() << endl;
			vecID[i].insert(vecID[i].end(), vecnewpoints.begin(), vecnewpoints.end());
			cout << "done the append vecnewpoints" << endl;
		}

		cout << "out of the if" << endl;
	}

	/*
	 * Up to this point, it is assumed that now we have the indexes in the vecID vector of vector of ints. We
	 * now start to build the table with the actual 2D points.
	 */

	*points = new vector<Mat>(vecID.size());

	for(unsigned int i = 0; i < vecID.size(); i++){
		//Defining the matrix for position i
		Mat_<double> mat(2,vecID[i].size());

		//Filling the matrix for position i
		for(unsigned int j = 0; j < vecID[i].size(); j++){
			mat(0,j) = (*veckeypoints)[i]->at(vecID[i][j]).pt.x;
			mat(1,j) = (*veckeypoints)[i]->at(vecID[i][j]).pt.y;
		}

		//Passing the matrix the matrix to position i in points
		(**points)[i] = mat;
	}


	return SUCCESS;
}


